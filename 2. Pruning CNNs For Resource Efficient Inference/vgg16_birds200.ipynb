{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# to create dataset\n",
    "read_line = open('./CUB_200_2011_updated/train_test_split.txt')\n",
    "train_test_split = read_line.readlines()\n",
    "\n",
    "classes = open('./CUB_200_2011_updated/classes.txt')\n",
    "c_names = classes.readlines()\n",
    "for i in range(len(c_names)):\n",
    "    c_names[i] = c_names[i].split(' ')[1]\n",
    "    \n",
    "import os\n",
    "for i in range(len(c_names)):\n",
    "    os.makedirs('./test/'+c_names[i].split('\\n')[0])\n",
    "    \n",
    "train_dataset = datasets.ImageFolder('./CUB_200_2011_updated/images')\n",
    "#len(train_dataset.imgs)\n",
    "for j in range(len(train_dataset.imgs)):\n",
    "    if(train_test_split[j].split(' ')[1].split('\\n')[0] == '0'):\n",
    "        path = train_dataset.imgs[j][0]\n",
    "        img = io.imread(path)\n",
    "        folder = train_dataset.imgs[j][0].split('/')[3]\n",
    "        img_name = train_dataset.imgs[j][0].split('/')[4]\n",
    "        io.imsave('./test/'+folder+'/'+img_name,img)\n",
    "        os.remove(path)\n",
    "!mv ./CUB_200_2011_updated/images ./train\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from heapq import nsmallest\n",
    "from operator import itemgetter\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import argparse\n",
    "import cv2\n",
    "import glob\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import collections\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, models, transforms\n",
    "import ipdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model and pruner class\n",
    "class ModifiedVGG16Model(torch.nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ModifiedVGG16Model, self).__init__()\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)  \n",
    "        self.features = model.features\n",
    "        self.classifier = model.classifier\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) \n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PrunningFineTuner_VGG16:\n",
    "    def __init__(self, train_path, test_path, model):\n",
    "        self.train_path=train_path\n",
    "        self.train_data_loader = train_loader(train_path)\n",
    "        self.test_data_loader = test_loader(test_path)\n",
    "        self.model = model\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.model.train() #set model in training mode\n",
    "        \n",
    "    def train(self, optimizer , epoches=10):\n",
    "        for i in range(epoches):\n",
    "            print(\"Epoch: \", i)\n",
    "            self.train_epoch(optimizer)\n",
    "            self.test()\n",
    "        print(\"Finished fine tuning.\")\n",
    "        \n",
    "    def train_epoch(self, optimizer=None, rank_filters = False):\n",
    "        for i, (batch, label) in enumerate(self.train_data_loader):\n",
    "            self.train_batch(optimizer, batch, label, rank_filters)\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        batch = batch.cuda()\n",
    "        label = label.cuda()\n",
    "        self.model.zero_grad()\n",
    "        if rank_filters: \n",
    "            output = self.forward(Variable(batch))\n",
    "            self.criterion(output, Variable(label)).backward() \n",
    "        else: \n",
    "            output=self.model(Variable(batch))\n",
    "            self.criterion(output, Variable(label)).backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        activation_index = 0\n",
    "        self.grad_index = 0 \n",
    "        self.activation_to_layer = {} #map from conv activation number to actual layer number\n",
    "        for layer, (name, module) in enumerate(self.model.features._modules.items()):\n",
    "            x = module(x)\n",
    "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
    "                x.register_hook(self.compute_rank) \n",
    "                self.activations.append(x)\n",
    "                self.activation_to_layer[activation_index] = layer\n",
    "                activation_index += 1\n",
    "        return self.model.classifier(x.view(x.size(0), -1))\n",
    "    \n",
    "    def compute_rank(self, grad):\n",
    "        activation_index = len(self.activations) - self.grad_index - 1\n",
    "        activation = self.activations[activation_index] \n",
    "        taylor = activation * grad  \n",
    "        ipdb.set_trace() #taylor is torch.Size([batch_size, 512, 14, 14])\n",
    "        taylor = taylor.mean(dim=(0, 2, 3)).data  #taylor is torch.Size([512])\n",
    "        if activation_index not in self.filter_ranks:\n",
    "            self.filter_ranks[activation_index] =  torch.FloatTensor(activation.size(1)).zero_()\n",
    "            self.filter_ranks[activation_index] = self.filter_ranks[activation_index].cuda()\n",
    "        self.filter_ranks[activation_index] += taylor #aAccumulate the taylor score over batch\n",
    "        self.grad_index += 1\n",
    "        \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (batch, label) in enumerate(self.test_data_loader):\n",
    "            batch = batch.cuda()\n",
    "            output = model(Variable(batch))\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.cpu().eq(label).sum()\n",
    "            total += label.size(0)\n",
    "        print(\"Accuracy on test set is :\", float(correct) / total)\n",
    "        self.model.train()\n",
    "        return float(correct) / total\n",
    "        \n",
    "    def train_mini_batch(self, optimizer, updates=30):\n",
    "        dataloader_iterator = iter(train_loader(self.train_path))\n",
    "        for i in range(updates):\n",
    "            try:\n",
    "                batch, label = next(dataloader_iterator)\n",
    "            except StopIteration:\n",
    "                dataloader_iterator = iter(train_loader(self.train_path))\n",
    "                batch, label = next(dataloader_iterator)\n",
    "            self.train_batch(optimizer, batch, label, False)           \n",
    "        self.test()\n",
    "        print(\"Finished fine tuning.\")\n",
    "        \n",
    "    def get_prunning_plan(self, num_filters_to_prune):\n",
    "        filters_to_prune = self.lowest_ranking_filters(num_filters_to_prune)\n",
    "        filters_to_prune_per_layer = collections.defaultdict(list)\n",
    "        for (l, f, _) in filters_to_prune: \n",
    "            filters_to_prune_per_layer[l].append(f)\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
    "            for i in range(len(filters_to_prune_per_layer[l])): \n",
    "                filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n",
    "        filters_to_prune = []\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            for i in filters_to_prune_per_layer[l]:\n",
    "                filters_to_prune.append((l, i))\n",
    "        return filters_to_prune  \n",
    "        \n",
    "    def normalize_ranks_per_layer(self):        \n",
    "        for i in self.filter_ranks:\n",
    "            v = torch.abs(self.filter_ranks[i])\n",
    "            v = v / torch.sqrt(torch.sum(v * v))\n",
    "            self.filter_ranks[i] = v.cpu()  \n",
    "            \n",
    "    def lowest_ranking_filters(self, num):\n",
    "        data = []\n",
    "        for i in sorted(self.filter_ranks.keys()):\n",
    "            for j in range(self.filter_ranks[i].size(0)):\n",
    "                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n",
    "        return nsmallest(num, data, itemgetter(2))\n",
    "        \n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.filter_ranks = {}\n",
    "        self.train_epoch(rank_filters = True)\n",
    "        self.normalize_ranks_per_layer()\n",
    "        return self.get_prunning_plan(num_filters_to_prune)\n",
    "        \n",
    "    def total_num_filters(self):\n",
    "        filters = 0\n",
    "        for name, module in self.model.features._modules.items():\n",
    "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
    "                filters = filters + module.out_channels\n",
    "        return filters\n",
    "\n",
    "    def prune(self,num_filters_to_prune_per_iteration=2,percentage_to_prune=67):\n",
    "        self.test() \n",
    "        self.model.train() \n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        number_of_filters = self.total_num_filters() \n",
    "        iterations = int(float(number_of_filters) / num_filters_to_prune_per_iteration)\n",
    "        iterations = int(iterations * percentage_to_prune * 0.01) \n",
    "        print(\"Number of prunning iterations to remove \"+ str(percentage_to_prune) +\"% filters : \", iterations)\n",
    "        for _ in range(iterations):\n",
    "            print(\"Ranking filters.. \")\n",
    "            prune_targets = self.get_candidates_to_prune(num_filters_to_prune_per_iteration)\n",
    "            layers_prunned = collections.defaultdict(int) \n",
    "            for layer_index, filter_index in prune_targets: \n",
    "                layers_prunned[layer_index] = layers_prunned[layer_index] + 1 \n",
    "            print(\"Layer number : number of filters in that layer that will be prunned\", layers_prunned)\n",
    "            print(\"Prunning filters.. \") \n",
    "            model = self.model.cpu()\n",
    "            for layer_index, filter_index in prune_targets:  #prune one filter at a time\n",
    "                model = self.prune_vgg16_conv_layer(model, layer_index, filter_index)\n",
    "            self.model = model\n",
    "            self.model = self.model.cuda()\n",
    "            message = str(100*float(self.total_num_filters()) / number_of_filters) + \"%\"\n",
    "            percentage=round(100*float(self.total_num_filters()) / number_of_filters,1)\n",
    "            print(\"Filters prunned\", str(message))\n",
    "            list_percentages_pruned.append(percentage)\n",
    "            list_test_acc_after_pruning.append(self.test())\n",
    "            print(\"Fine tuning to recover from prunning iteration.\")\n",
    "            optimizer = optim.SGD(self.model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
    "            self.train_mini_batch(optimizer, updates=30)\n",
    "        print(\"Finished. Going to fine tune the model a bit more\")\n",
    "        #self.train(optimizer, epoches=15)\n",
    "        \n",
    "    def prune_vgg16_conv_layer(self,model, layer_index, filter_index):\n",
    "        _, conv = list(model.features._modules.items())[layer_index] #pluck out the current conv layer given by layer_index\n",
    "        next_conv = None\n",
    "        offset = 1 \n",
    "        while layer_index + offset <  len(model.features._modules.items()): #check  if layer number (layer_index + offset) would be a valid layer\n",
    "            res =  list(model.features._modules.items())[layer_index+offset] #pluck out one of the next layers\n",
    "            if isinstance(res[1], torch.nn.modules.conv.Conv2d): #check  if next layer is a conv layer\n",
    "                next_name, next_conv = res #if so, save it and break the loop\n",
    "                break\n",
    "            offset = offset + 1\n",
    "        new_conv = torch.nn.Conv2d(in_channels = conv.in_channels, out_channels = conv.out_channels - 1, #main change\n",
    "                kernel_size = conv.kernel_size, stride = conv.stride, padding = conv.padding, dilation = conv.dilation,\n",
    "                groups = conv.groups, bias = (conv.bias is not None)) #bias is boolean arg. use bias if original conv had bias\n",
    "        old_weights = conv.weight.data.cpu().numpy()\n",
    "        new_weights = new_conv.weight.data.cpu().numpy() #would be random to begin with. xavier init\n",
    "\n",
    "        new_weights[: filter_index, :, :, :] = old_weights[: filter_index, :, :, :]\n",
    "        new_weights[filter_index : , :, :, :] = old_weights[filter_index + 1 :, :, :, :] #skip filter_index weights in old_weights\n",
    "        new_conv.weight.data = torch.from_numpy(new_weights)  # save new_weights to new_conv\n",
    "        new_conv.weight.data = new_conv.weight.data.cuda() #hard code use cuda\n",
    "\n",
    "        bias_numpy = conv.bias.data.cpu().numpy() #old bias\n",
    "\n",
    "        bias = np.zeros(shape = (bias_numpy.shape[0] - 1), dtype = np.float32) #one less bias. initialize a vector of zeros of same size\n",
    "        bias[:filter_index] = bias_numpy[:filter_index]\n",
    "        bias[filter_index : ] = bias_numpy[filter_index + 1 :] #skip bias_numpy[filter_index]\n",
    "        new_conv.bias.data = torch.from_numpy(bias) #save to new_conv\n",
    "        new_conv.bias.data = new_conv.bias.data.cuda() #hardcode cuda\n",
    "\n",
    "        if not next_conv is None: #if next layer is a conv\n",
    "            next_new_conv = torch.nn.Conv2d(in_channels = next_conv.in_channels - 1, #make a new conv with one less in_channels\n",
    "                    out_channels =  next_conv.out_channels, kernel_size = next_conv.kernel_size, stride = next_conv.stride,\n",
    "                    padding = next_conv.padding, dilation = next_conv.dilation, groups = next_conv.groups, bias = (next_conv.bias is not None))\n",
    "\n",
    "            old_weights = next_conv.weight.data.cpu().numpy()\n",
    "            new_weights = next_new_conv.weight.data.cpu().numpy()\n",
    "\n",
    "            new_weights[:, : filter_index, :, :] = old_weights[:, : filter_index, :, :]\n",
    "            new_weights[:, filter_index : , :, :] = old_weights[:, filter_index + 1 :, :, :]\n",
    "            next_new_conv.weight.data = torch.from_numpy(new_weights)\n",
    "            next_new_conv.weight.data = next_new_conv.weight.data.cuda()\n",
    "\n",
    "            next_new_conv.bias.data = next_conv.bias.data  #no change is bias. copy over\n",
    "            features_list=[]\n",
    "            for i, _ in enumerate(model.features): #stitch the network back together\n",
    "                features_list.append(self.replace_layers(model.features, i, [layer_index, layer_index+offset], [new_conv, next_new_conv]))\n",
    "\n",
    "            features = torch.nn.Sequential(*(features_list)) \n",
    "            del model.features #free memory\n",
    "            del conv\n",
    "\n",
    "            model.features = features\n",
    "        else: #Prunning the last conv layer. This affects the first linear layer of the classifier. now features_list would have only 1 new conv layer to replace in\n",
    "            features_list=[]\n",
    "            for i, _ in enumerate(model.features):\n",
    "                features_list.append(self.replace_layers(model.features, i, [layer_index],[new_conv]))\n",
    "            model.features = torch.nn.Sequential(*(features_list))\n",
    "\n",
    "            layer_index = 0\n",
    "            old_linear_layer = None\n",
    "            for _, module in model.classifier._modules.items():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    old_linear_layer = module\n",
    "                    break #find the first occurance of linear_layer and break\n",
    "                layer_index = layer_index  + 1\n",
    "\n",
    "            if old_linear_layer is None:\n",
    "                raise BaseException(\"No linear layer found in classifier\")\n",
    "            params_per_input_channel = old_linear_layer.in_features // conv.out_channels\n",
    "\n",
    "            new_linear_layer = torch.nn.Linear(old_linear_layer.in_features - params_per_input_channel, old_linear_layer.out_features)\n",
    "\n",
    "            old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
    "            new_weights = new_linear_layer.weight.data.cpu().numpy()        \n",
    "\n",
    "            new_weights[:, : filter_index * params_per_input_channel] = old_weights[:, : filter_index * params_per_input_channel]\n",
    "            new_weights[:, filter_index * params_per_input_channel :] = old_weights[:, (filter_index + 1) * params_per_input_channel :]\n",
    "\n",
    "            new_linear_layer.bias.data = old_linear_layer.bias.data #bias remains same\n",
    "\n",
    "            new_linear_layer.weight.data = torch.from_numpy(new_weights) #save the new weights in FC layer object\n",
    "            new_linear_layer.weight.data = new_linear_layer.weight.data.cuda() #hard code cuda\n",
    "\n",
    "            classifier_list=[]\n",
    "            for i, _ in enumerate(model.classifier):\n",
    "                classifier_list.append(self.replace_layers(model.classifier, i, [layer_index],[new_linear_layer]))\n",
    "\n",
    "            classifier = torch.nn.Sequential(*(classifier_list))\n",
    "\n",
    "            del model.classifier\n",
    "            del next_conv\n",
    "            del conv\n",
    "            model.classifier = classifier\n",
    "        return model\n",
    "    def replace_layers(self,model, i, indexes, layers):\n",
    "        if i in indexes:\n",
    "            return layers[indexes.index(i)]\n",
    "        return model[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def train_loader(path, batch_size=32, num_workers=4, pin_memory=True):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return data.DataLoader(\n",
    "        datasets.ImageFolder(path,\n",
    "                             transforms.Compose([\n",
    "                                 transforms.Resize(256),\n",
    "                                 transforms.RandomRotation(45),\n",
    "                                 transforms.RandomResizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize,\n",
    "                             ])),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)\n",
    "\n",
    "def test_loader(path, batch_size=128, num_workers=4, pin_memory=True):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return data.DataLoader(\n",
    "        datasets.ImageFolder(path,\n",
    "                             transforms.Compose([\n",
    "                                 transforms.Resize(256),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize,\n",
    "                             ])),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Accuracy : 0.17500862961684502\n",
      "Epoch:  1\n",
      "Accuracy : 0.3938557128063514\n",
      "Epoch:  2\n",
      "Accuracy : 0.49982740766309974\n",
      "Epoch:  3\n",
      "Accuracy : 0.5479806696582672\n",
      "Epoch:  4\n",
      "Accuracy : 0.5966517086641353\n",
      "Epoch:  5\n",
      "Accuracy : 0.6251294442526751\n",
      "Epoch:  6\n",
      "Accuracy : 0.6213324128408698\n",
      "Epoch:  7\n",
      "Accuracy : 0.6325509147393855\n",
      "Epoch:  8\n",
      "Accuracy : 0.6556782878840179\n",
      "Epoch:  9\n",
      "Accuracy : 0.6701760441836383\n",
      "Epoch:  10\n",
      "Accuracy : 0.6468760787021056\n",
      "Epoch:  11\n",
      "Accuracy : 0.6845012081463583\n",
      "Epoch:  12\n",
      "Accuracy : 0.6939937866758716\n",
      "Epoch:  13\n",
      "Accuracy : 0.6889886089057646\n",
      "Epoch:  14\n",
      "Accuracy : 0.7148774594408008\n",
      "Epoch:  15\n",
      "Accuracy : 0.7072833966171902\n",
      "Epoch:  16\n",
      "Accuracy : 0.7072833966171902\n",
      "Epoch:  17\n",
      "Accuracy : 0.7110804280289955\n",
      "Epoch:  18\n",
      "Accuracy : 0.711425612702796\n",
      "Epoch:  19\n",
      "Accuracy : 0.7195374525371073\n",
      "Epoch:  20\n",
      "Accuracy : 0.7096996893337936\n",
      "Epoch:  21\n",
      "Accuracy : 0.7248878149810148\n",
      "Epoch:  22\n",
      "Accuracy : 0.7138419054193994\n",
      "Epoch:  23\n",
      "Accuracy : 0.726441146013117\n",
      "Epoch:  24\n",
      "Accuracy : 0.7238522609596134\n",
      "Epoch:  25\n",
      "Accuracy : 0.7160856057991025\n",
      "Epoch:  26\n",
      "Accuracy : 0.7226441146013117\n",
      "Epoch:  27\n",
      "Accuracy : 0.7240248532965137\n",
      "Epoch:  28\n",
      "Accuracy : 0.7324818778046255\n",
      "Epoch:  29\n",
      "Accuracy : 0.7390403866068347\n",
      "Epoch:  30\n",
      "Accuracy : 0.7319641007939247\n",
      "Epoch:  31\n",
      "Accuracy : 0.7243700379703141\n",
      "Epoch:  32\n",
      "Accuracy : 0.7369692785640317\n",
      "Epoch:  33\n",
      "Accuracy : 0.7323092854677252\n",
      "Epoch:  34\n",
      "Accuracy : 0.7393855712806351\n",
      "Epoch:  35\n",
      "Accuracy : 0.7117707973765964\n",
      "Epoch:  36\n",
      "Accuracy : 0.7250604073179151\n",
      "Epoch:  37\n",
      "Accuracy : 0.7331722471522264\n",
      "Epoch:  38\n",
      "Accuracy : 0.7418018639972386\n",
      "Epoch:  39\n",
      "Accuracy : 0.7342078011736279\n",
      "Epoch:  40\n",
      "Accuracy : 0.7376596479116327\n",
      "Epoch:  41\n",
      "Accuracy : 0.7359337245426303\n",
      "Epoch:  42\n",
      "Accuracy : 0.7290300310666207\n",
      "Epoch:  43\n",
      "Accuracy : 0.7283396617190196\n",
      "Epoch:  44\n",
      "Accuracy : 0.7338626164998274\n",
      "Epoch:  45\n",
      "Accuracy : 0.7361063168795305\n",
      "Epoch:  46\n",
      "Accuracy : 0.7300655850880221\n",
      "Epoch:  47\n",
      "Accuracy : 0.7388677942699344\n",
      "Epoch:  48\n",
      "Accuracy : 0.7376596479116327\n",
      "Epoch:  49\n",
      "Accuracy : 0.7367966862271316\n",
      "Epoch:  50\n",
      "Accuracy : 0.7424922333448395\n",
      "Epoch:  51\n",
      "Accuracy : 0.7305833620987228\n",
      "Epoch:  52\n",
      "Accuracy : 0.732136693130825\n",
      "Epoch:  53\n",
      "Accuracy : 0.7359337245426303\n",
      "Epoch:  54\n",
      "Accuracy : 0.7386952019330342\n",
      "Epoch:  55\n",
      "Accuracy : 0.7385226095961339\n",
      "Epoch:  56\n",
      "Accuracy : 0.7397307559544356\n",
      "Epoch:  57\n",
      "Accuracy : 0.7402485329651364\n",
      "Epoch:  58\n",
      "Accuracy : 0.7430100103555403\n",
      "Epoch:  59\n",
      "Accuracy : 0.7419744563341387\n",
      "Finished fine tuning.\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedVGG16Model(num_classes=200)\n",
    "model = model.cuda()\n",
    "initial_training_obj = PrunningFineTuner_VGG16(\"train\", \"test\", model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "initial_training_obj.train(optimizer,epoches=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7419744563341387\n"
     ]
    }
   ],
   "source": [
    "initial_training_obj.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'state_dict': model.state_dict()}, 'checkpoint_models/trained_model_state.pt') #save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is : 0.7419744563341387\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedVGG16Model(num_classes=200)\n",
    "model = model.cuda()\n",
    "checkpoint = torch.load('checkpoint_models/trained_model_state.pt') #load\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model=model.cuda()\n",
    "pruner_obj = PrunningFineTuner_VGG16(\"train\", \"test\", model)\n",
    "pruner_obj.test()\n",
    "list_test_acc_after_pruning=[]\n",
    "list_percentages_pruned=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is : 0.7419744563341387\n",
      "Number of prunning iterations to remove 99% filters :  130\n",
      "Ranking filters.. \n",
      "> \u001b[0;32m<ipython-input-8-f8b18bbb378b>\u001b[0m(52)\u001b[0;36mcompute_rank\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     51 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 52 \u001b[0;31m        \u001b[0mtaylor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaylor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mactivation_index\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_ranks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> taylor.shape\n",
      "torch.Size([32, 512, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "pruner_obj.prune(percentage_to_prune=99, num_filters_to_prune_per_iteration=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aeb1848fc90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list_percentages_pruned[:-1],list_test_acc_after_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.740766309975837,\n",
       " 0.7488781498101484,\n",
       " 0.750776665516051,\n",
       " 0.7462892647566448,\n",
       " 0.7502588885053504,\n",
       " 0.7511218501898516,\n",
       " 0.752157404211253,\n",
       " 0.7575077666551605,\n",
       " 0.7538833275802554,\n",
       " 0.7526751812219538,\n",
       " 0.7538833275802554,\n",
       " 0.7537107352433552,\n",
       " 0.7549188816016569,\n",
       " 0.7483603727994477,\n",
       " 0.7493959268208491,\n",
       " 0.7464618570935451,\n",
       " 0.7537107352433552,\n",
       " 0.7523299965481532,\n",
       " 0.7531929582326544,\n",
       " 0.7575077666551605,\n",
       " 0.7511218501898516,\n",
       " 0.7554366586123576,\n",
       " 0.7575077666551605,\n",
       " 0.7587159130134622,\n",
       " 0.7564722126337591,\n",
       " 0.7549188816016569,\n",
       " 0.7550914739385571,\n",
       " 0.7569899896444597,\n",
       " 0.7535381429064549,\n",
       " 0.7540559199171557,\n",
       " 0.7538833275802554,\n",
       " 0.7526751812219538,\n",
       " 0.7562996202968588,\n",
       " 0.7535381429064549,\n",
       " 0.7535381429064549,\n",
       " 0.7509492578529513,\n",
       " 0.7533655505695547,\n",
       " 0.7514670348636521,\n",
       " 0.7511218501898516,\n",
       " 0.7556092509492579,\n",
       " 0.7575077666551605,\n",
       " 0.7568173973075596,\n",
       " 0.7531929582326544,\n",
       " 0.7526751812219538,\n",
       " 0.752157404211253,\n",
       " 0.7576803589920608,\n",
       " 0.7525025888850535,\n",
       " 0.7573351743182603,\n",
       " 0.7495685191577494,\n",
       " 0.7518122195374526,\n",
       " 0.7549188816016569,\n",
       " 0.7547462892647566,\n",
       " 0.7549188816016569,\n",
       " 0.7518122195374526,\n",
       " 0.7504314808422506,\n",
       " 0.7587159130134622,\n",
       " 0.7544011045909561,\n",
       " 0.755781843286158,\n",
       " 0.7533655505695547,\n",
       " 0.7549188816016569,\n",
       " 0.7523299965481532,\n",
       " 0.7580255436658613,\n",
       " 0.7556092509492579,\n",
       " 0.7568173973075596,\n",
       " 0.7569899896444597,\n",
       " 0.7538833275802554,\n",
       " 0.7561270279599586,\n",
       " 0.745771487745944,\n",
       " 0.752157404211253,\n",
       " 0.752847773558854,\n",
       " 0.7493959268208491,\n",
       " 0.7514670348636521,\n",
       " 0.7523299965481532,\n",
       " 0.7533655505695547,\n",
       " 0.7544011045909561,\n",
       " 0.754228512254056,\n",
       " 0.7488781498101484,\n",
       " 0.7466344494304453,\n",
       " 0.7511218501898516,\n",
       " 0.7512944425267518,\n",
       " 0.752847773558854,\n",
       " 0.7535381429064549,\n",
       " 0.7554366586123576,\n",
       " 0.7493959268208491,\n",
       " 0.7483603727994477,\n",
       " 0.7512944425267518,\n",
       " 0.7549188816016569,\n",
       " 0.7526751812219538,\n",
       " 0.750776665516051,\n",
       " 0.7474974111149465,\n",
       " 0.7480151881256473,\n",
       " 0.7502588885053504,\n",
       " 0.7516396272005523,\n",
       " 0.7488781498101484,\n",
       " 0.7518122195374526,\n",
       " 0.7518122195374526,\n",
       " 0.7526751812219538,\n",
       " 0.7518122195374526,\n",
       " 0.7530203658957543,\n",
       " 0.7540559199171557,\n",
       " 0.7497411114946496,\n",
       " 0.7523299965481532,\n",
       " 0.7488781498101484,\n",
       " 0.7518122195374526,\n",
       " 0.7502588885053504,\n",
       " 0.7490507421470487,\n",
       " 0.7461166724197446,\n",
       " 0.7512944425267518,\n",
       " 0.7469796341042457,\n",
       " 0.7490507421470487,\n",
       " 0.7485329651363479,\n",
       " 0.745771487745944,\n",
       " 0.7530203658957543,\n",
       " 0.749223334483949,\n",
       " 0.7481877804625474,\n",
       " 0.7469796341042457,\n",
       " 0.7481877804625474,\n",
       " 0.750776665516051,\n",
       " 0.7435277873662409,\n",
       " 0.7426648256817397,\n",
       " 0.7493959268208491,\n",
       " 0.750776665516051,\n",
       " 0.7468070417673456,\n",
       " 0.7449085260614429,\n",
       " 0.7493959268208491,\n",
       " 0.7481877804625474,\n",
       " 0.7481877804625474,\n",
       " 0.7511218501898516,\n",
       " 0.7485329651363479,\n",
       " 0.7488781498101484,\n",
       " 0.7497411114946496,\n",
       " 0.7485329651363479,\n",
       " 0.745771487745944,\n",
       " 0.7487055574732482,\n",
       " 0.7466344494304453,\n",
       " 0.7468070417673456,\n",
       " 0.7459440800828443,\n",
       " 0.7452537107352434,\n",
       " 0.7464618570935451,\n",
       " 0.7462892647566448,\n",
       " 0.7468070417673456,\n",
       " 0.7509492578529513,\n",
       " 0.747842595788747,\n",
       " 0.7468070417673456,\n",
       " 0.7487055574732482,\n",
       " 0.750776665516051,\n",
       " 0.7500862961684501,\n",
       " 0.7452537107352434,\n",
       " 0.7469796341042457,\n",
       " 0.7488781498101484,\n",
       " 0.7468070417673456,\n",
       " 0.7480151881256473,\n",
       " 0.7464618570935451,\n",
       " 0.7504314808422506,\n",
       " 0.7474974111149465,\n",
       " 0.7462892647566448,\n",
       " 0.7476700034518468,\n",
       " 0.752847773558854,\n",
       " 0.7506040731791509,\n",
       " 0.7500862961684501,\n",
       " 0.7469796341042457,\n",
       " 0.7464618570935451,\n",
       " 0.7523299965481532,\n",
       " 0.7525025888850535,\n",
       " 0.7499137038315499,\n",
       " 0.7487055574732482,\n",
       " 0.7518122195374526,\n",
       " 0.7450811183983431,\n",
       " 0.7426648256817397,\n",
       " 0.7430100103555403,\n",
       " 0.7452537107352434,\n",
       " 0.7473248187780462,\n",
       " 0.747842595788747,\n",
       " 0.7485329651363479,\n",
       " 0.7504314808422506,\n",
       " 0.752847773558854,\n",
       " 0.747152226441146,\n",
       " 0.7468070417673456,\n",
       " 0.7545736969278564,\n",
       " 0.7509492578529513,\n",
       " 0.7490507421470487,\n",
       " 0.7488781498101484,\n",
       " 0.7509492578529513,\n",
       " 0.747842595788747,\n",
       " 0.747842595788747,\n",
       " 0.7474974111149465,\n",
       " 0.749223334483949,\n",
       " 0.7490507421470487,\n",
       " 0.7464618570935451,\n",
       " 0.7418018639972386,\n",
       " 0.7437003797031412,\n",
       " 0.7485329651363479,\n",
       " 0.7488781498101484,\n",
       " 0.745771487745944,\n",
       " 0.745771487745944,\n",
       " 0.7502588885053504,\n",
       " 0.7468070417673456,\n",
       " 0.7487055574732482,\n",
       " 0.7488781498101484,\n",
       " 0.7490507421470487,\n",
       " 0.7544011045909561,\n",
       " 0.7438729720400414,\n",
       " 0.7464618570935451,\n",
       " 0.7552640662754574,\n",
       " 0.7481877804625474,\n",
       " 0.7450811183983431,\n",
       " 0.7455988954090439,\n",
       " 0.7481877804625474,\n",
       " 0.7481877804625474,\n",
       " 0.7488781498101484,\n",
       " 0.7500862961684501,\n",
       " 0.7469796341042457,\n",
       " 0.745771487745944,\n",
       " 0.7506040731791509,\n",
       " 0.7490507421470487,\n",
       " 0.7502588885053504,\n",
       " 0.7476700034518468,\n",
       " 0.7438729720400414,\n",
       " 0.7466344494304453,\n",
       " 0.7500862961684501,\n",
       " 0.744218156713842,\n",
       " 0.742147048671039,\n",
       " 0.7437003797031412,\n",
       " 0.7480151881256473,\n",
       " 0.7500862961684501,\n",
       " 0.7481877804625474,\n",
       " 0.7502588885053504,\n",
       " 0.747842595788747,\n",
       " 0.747152226441146,\n",
       " 0.7452537107352434,\n",
       " 0.74283741801864,\n",
       " 0.747152226441146,\n",
       " 0.7483603727994477,\n",
       " 0.745771487745944,\n",
       " 0.7518122195374526,\n",
       " 0.7476700034518468,\n",
       " 0.74283741801864,\n",
       " 0.744218156713842,\n",
       " 0.7424922333448395,\n",
       " 0.747152226441146,\n",
       " 0.749223334483949,\n",
       " 0.745771487745944,\n",
       " 0.749223334483949,\n",
       " 0.7443907490507421,\n",
       " 0.7502588885053504,\n",
       " 0.7512944425267518,\n",
       " 0.7474974111149465,\n",
       " 0.7437003797031412,\n",
       " 0.749223334483949,\n",
       " 0.7502588885053504,\n",
       " 0.7490507421470487,\n",
       " 0.7497411114946496,\n",
       " 0.750776665516051,\n",
       " 0.7438729720400414,\n",
       " 0.7452537107352434,\n",
       " 0.7497411114946496,\n",
       " 0.7461166724197446,\n",
       " 0.7500862961684501,\n",
       " 0.7424922333448395,\n",
       " 0.749223334483949,\n",
       " 0.7483603727994477,\n",
       " 0.7504314808422506,\n",
       " 0.7531929582326544,\n",
       " 0.7493959268208491,\n",
       " 0.747842595788747,\n",
       " 0.7468070417673456,\n",
       " 0.7476700034518468,\n",
       " 0.7495685191577494,\n",
       " 0.7488781498101484,\n",
       " 0.74283741801864,\n",
       " 0.7526751812219538,\n",
       " 0.7499137038315499,\n",
       " 0.7516396272005523,\n",
       " 0.7533655505695547,\n",
       " 0.747842595788747,\n",
       " 0.7437003797031412,\n",
       " 0.7466344494304453,\n",
       " 0.7088367276492924,\n",
       " 0.7295478080773213,\n",
       " 0.7312737314463238,\n",
       " 0.7274767000345185,\n",
       " 0.7331722471522264,\n",
       " 0.7412840869865378,\n",
       " 0.7405937176389368,\n",
       " 0.7352433551950294,\n",
       " 0.7386952019330342,\n",
       " 0.7373144632378322,\n",
       " 0.7412840869865378,\n",
       " 0.7347255781843286,\n",
       " 0.7329996548153263,\n",
       " 0.732827062478426,\n",
       " 0.740766309975837,\n",
       " 0.7374870555747325,\n",
       " 0.7333448394891267,\n",
       " 0.7395581636175353,\n",
       " 0.7388677942699344,\n",
       " 0.7336900241629272,\n",
       " 0.73576113220573,\n",
       " 0.7366240938902313,\n",
       " 0.73576113220573,\n",
       " 0.7348981705212289,\n",
       " 0.7431826026924404,\n",
       " 0.7369692785640317,\n",
       " 0.7426648256817397,\n",
       " 0.7443907490507421,\n",
       " 0.7402485329651364,\n",
       " 0.7419744563341387,\n",
       " 0.745771487745944,\n",
       " 0.7388677942699344,\n",
       " 0.7424922333448395,\n",
       " 0.7397307559544356,\n",
       " 0.7405937176389368,\n",
       " 0.7412840869865378,\n",
       " 0.7454263030721436,\n",
       " 0.7355885398688298,\n",
       " 0.7411114946496375,\n",
       " 0.7364515015533311,\n",
       " 0.7411114946496375,\n",
       " 0.7435277873662409,\n",
       " 0.7426648256817397,\n",
       " 0.7373144632378322,\n",
       " 0.7374870555747325,\n",
       " 0.7323092854677252,\n",
       " 0.7373144632378322,\n",
       " 0.7376596479116327,\n",
       " 0.7393855712806351,\n",
       " 0.7383500172592337,\n",
       " 0.7386952019330342,\n",
       " 0.7366240938902313,\n",
       " 0.7347255781843286,\n",
       " 0.7376596479116327,\n",
       " 0.7418018639972386,\n",
       " 0.7361063168795305,\n",
       " 0.7386952019330342,\n",
       " 0.7393855712806351,\n",
       " 0.7426648256817397,\n",
       " 0.7435277873662409,\n",
       " 0.7399033482913359,\n",
       " 0.7416292716603383,\n",
       " 0.7354159475319296,\n",
       " 0.7392129789437349,\n",
       " 0.7388677942699344,\n",
       " 0.7461166724197446,\n",
       " 0.7411114946496375,\n",
       " 0.7469796341042457,\n",
       " 0.7424922333448395,\n",
       " 0.7354159475319296,\n",
       " 0.7340352088367277,\n",
       " 0.740766309975837,\n",
       " 0.745771487745944,\n",
       " 0.7409389023127373,\n",
       " 0.7435277873662409,\n",
       " 0.7419744563341387,\n",
       " 0.7433551950293407,\n",
       " 0.737832240248533,\n",
       " 0.7423196410079392,\n",
       " 0.7367966862271316,\n",
       " 0.7390403866068347,\n",
       " 0.7343803935105281,\n",
       " 0.7402485329651364,\n",
       " 0.737141870900932,\n",
       " 0.7395581636175353,\n",
       " 0.7364515015533311,\n",
       " 0.7390403866068347,\n",
       " 0.7440455643769417,\n",
       " 0.744218156713842,\n",
       " 0.7466344494304453,\n",
       " 0.749223334483949,\n",
       " 0.7480151881256473,\n",
       " 0.742147048671039,\n",
       " 0.7464618570935451,\n",
       " 0.7449085260614429,\n",
       " 0.7440455643769417,\n",
       " 0.7404211253020366,\n",
       " 0.7418018639972386,\n",
       " 0.7409389023127373]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_test_acc_after_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'checkpoint_models/pruned_model.pt') \n",
    "#save entire model since this is a custom model which would be lost after kernel stops. \n",
    "# will have to reprune to get it back. not deterministic. \n",
    "#ignore the warning below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model=torch.load('checkpoint_models/pruned_model.pt') \n",
    "model = pruned_model.cuda()\n",
    "pruner_obj = PrunningFineTuner_VGG16(\"train\", \"test\", model)\n",
    "pruner_obj.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholder\n",
    "ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#future\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Cub2011(Dataset):\n",
    "    base_folder = 'CUB_200_2011/images'\n",
    "    url = 'http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz'\n",
    "    filename = 'CUB_200_2011.tgz'\n",
    "    tgz_md5 = '97eceeb196236b17998738112f37df78'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, loader=default_loader, download=True):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.loader = default_loader\n",
    "        self.train = train\n",
    "\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        images = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'images.txt'), sep=' ',\n",
    "                             names=['img_id', 'filepath'])\n",
    "        image_class_labels = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'image_class_labels.txt'),\n",
    "                                         sep=' ', names=['img_id', 'target'])\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'train_test_split.txt'),\n",
    "                                       sep=' ', names=['img_id', 'is_training_img'])\n",
    "\n",
    "        data = images.merge(image_class_labels, on='img_id')\n",
    "        self.data = data.merge(train_test_split, on='img_id')\n",
    "\n",
    "        if self.train:\n",
    "            self.data = self.data[self.data.is_training_img == 1]\n",
    "        else:\n",
    "            self.data = self.data[self.data.is_training_img == 0]\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        try:\n",
    "            self._load_metadata()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            filepath = os.path.join(self.root, self.base_folder, row.filepath)\n",
    "            if not os.path.isfile(filepath):\n",
    "                print(filepath)\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        download_url(self.url, self.root, self.filename, self.tgz_md5)\n",
    "\n",
    "        with tarfile.open(os.path.join(self.root, self.filename), \"r:gz\") as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        path = os.path.join(self.root, self.base_folder, sample.filepath)\n",
    "        target = sample.target - 1  # Targets start at 1 by default, so shift to 0\n",
    "        img = self.loader(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "Cub2011_dataset_train=Cub2011('/scratch/arora.roh/dl_compression/prune2/bird-200-2011', train=True, transform=None, loader=default_loader, download=True)\n",
    "Cub2011_dataset_test=Cub2011('/scratch/arora.roh/dl_compression/prune2/bird-200-2011', train=False, transform=None, loader=default_loader, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
